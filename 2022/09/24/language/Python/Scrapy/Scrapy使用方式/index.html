<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Scrapy 基础知识 - 路由器</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="路由器"><meta name="msapplication-TileImage" content="/img/avatar.png"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="路由器"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="介绍scrapy框架核心租价、基本命令、代码编写、以及各个组件的执行顺序"><meta property="og:type" content="blog"><meta property="og:title" content="Scrapy 基础知识"><meta property="og:url" content="http://example.com/2022/09/24/language/Python/Scrapy/Scrapy%E4%BD%BF%E7%94%A8%E6%96%B9%E5%BC%8F/"><meta property="og:site_name" content="路由器"><meta property="og:description" content="介绍scrapy框架核心租价、基本命令、代码编写、以及各个组件的执行顺序"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="http://example.com/workspace/blog/source/images/Scrapy%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/e1868b22bb82ef7f1eacb68dc2086499.png"><meta property="article:published_time" content="2022-09-23T16:00:00.000Z"><meta property="article:modified_time" content="2022-09-26T12:57:57.507Z"><meta property="article:author" content="路由器"><meta property="article:tag" content="爬虫"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/workspace/blog/source/images/Scrapy%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/e1868b22bb82ef7f1eacb68dc2086499.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://example.com/2022/09/24/language/Python/Scrapy/Scrapy%E4%BD%BF%E7%94%A8%E6%96%B9%E5%BC%8F/"},"headline":"Scrapy 基础知识","image":["http://example.com/workspace/blog/source/images/Scrapy%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/e1868b22bb82ef7f1eacb68dc2086499.png"],"datePublished":"2022-09-23T16:00:00.000Z","dateModified":"2022-09-26T12:57:57.507Z","author":{"@type":"Person","name":"路由器"},"publisher":{"@type":"Organization","name":"路由器","logo":{"@type":"ImageObject","url":"http://example.com/img/avatar.png"}},"description":"介绍scrapy框架核心租价、基本命令、代码编写、以及各个组件的执行顺序"}</script><link rel="canonical" href="http://example.com/2022/09/24/language/Python/Scrapy/Scrapy%E4%BD%BF%E7%94%A8%E6%96%B9%E5%BC%8F/"><link rel="icon" href="/img/avatar.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }
          Array
              .from(document.querySelectorAll('.tab-content'))
              .forEach($tab => {
                  $tab.classList.add('is-hidden');
              });
          Array
              .from(document.querySelectorAll('.tabs li'))
              .forEach($tab => {
                  $tab.classList.remove('is-active');
              });
          const $activeTab = document.querySelector(location.hash);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
          const $tabMenu = document.querySelector(`a[href="${location.hash}"]`);
          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.2.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/avatar.png" alt="路由器" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2022-09-23T16:00:00.000Z" title="2022/9/24 00:00:00">2022-09-24</time>发表</span><span class="level-item"><time dateTime="2022-09-26T12:57:57.507Z" title="2022/9/26 20:57:57">2022-09-26</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/Python/">Python</a><span> / </span><a class="link-muted" href="/categories/Python/Scrapy/">Scrapy</a></span><span class="level-item">17 分钟读完 (大约2580个字)</span></div></div><h1 class="title is-3 is-size-4-mobile">Scrapy 基础知识</h1><div class="content"><p>介绍<code>scrapy</code>框架核心租价、基本命令、代码编写、以及各个组件的执行顺序</p>
<span id="more"></span>

<h1 id="Scrapy-基础知识"><a href="#Scrapy-基础知识" class="headerlink" title="Scrapy 基础知识"></a>Scrapy 基础知识</h1><h2 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h2><p>如果没有安装过<code>scrapy</code>应先执行</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">pip install scrapy</span></span><br></pre></td></tr></table></figure>

<h3 id="创建爬虫工程"><a href="#创建爬虫工程" class="headerlink" title="创建爬虫工程"></a>创建爬虫工程</h3><p>该命令会在<code>spiders</code>下新建爬虫文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">scrapy startproject 工程名</span></span><br></pre></td></tr></table></figure>

<p><strong>举例</strong>：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">scrapy genspider bilibili_test</span></span><br></pre></td></tr></table></figure>

<h3 id="创建爬虫文件"><a href="#创建爬虫文件" class="headerlink" title="创建爬虫文件"></a>创建爬虫文件</h3><p>该命令会在<code>spiders</code>下新建爬虫文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">scrapy genspider 爬虫文件名 目标网站</span></span><br></pre></td></tr></table></figure>

<p><strong>举例</strong>：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">scrapy genspider bilibili www.bilibili.com</span></span><br></pre></td></tr></table></figure>

<h3 id="执行爬虫"><a href="#执行爬虫" class="headerlink" title="执行爬虫"></a>执行爬虫</h3><p>该命令会在<code>spiders</code>下新建爬虫文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">scrapy crawl 爬虫文件名(不需要后缀)</span></span><br></pre></td></tr></table></figure>

<p><strong>参数</strong>：</p>
<ul>
<li>**–nolog:**不输出日志</li>
<li>**-o:**将<code>parse()</code>方法的返回值存储到指定输出文件，可以选择下列文件格式：<ul>
<li><code>csv</code></li>
<li><code>json</code></li>
<li><code>xml</code></li>
<li><code>jl</code></li>
<li><code>jsonlines</code></li>
<li><code>marshal</code></li>
<li><code>pickle</code></li>
</ul>
</li>
</ul>
<p><strong>举例</strong>：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">scrapy crawl bilibili</span></span><br></pre></td></tr></table></figure>

<h2 id="项目结构"><a href="#项目结构" class="headerlink" title="项目结构"></a>项目结构</h2><p>创建爬虫工程后得到目录结构如下;</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="string">工程名:</span></span><br><span class="line">	<span class="attr">spiders:</span> 			<span class="comment">#爬虫文件目录</span></span><br><span class="line">		<span class="string">__init__.py</span></span><br><span class="line">		<span class="string">爬虫文件.py</span>		 <span class="comment">#爬虫网站数据以及数据解析逻辑，将数据封装成item</span></span><br><span class="line">	<span class="string">__init__.py</span>  </span><br><span class="line">	<span class="string">items.py</span>  			<span class="comment">#数据封装对象</span></span><br><span class="line">	<span class="string">middlewares.py</span>  </span><br><span class="line">	<span class="string">pipelines.py</span>		<span class="comment">#管道，用于处理item类型对象，进行持久化</span></span><br><span class="line">	<span class="string">settings.py</span>  		<span class="comment">#爬虫配置</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">main.py</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">scrapy.cfg</span></span><br></pre></td></tr></table></figure>

<p>项目包含的<code>py</code>文件中初始化了对应的类，在这些类中实现重写相应方法的逻辑代码，<code>scrapy</code>会按照顺序调用这些方法</p>
<h2 id="核心组件"><a href="#核心组件" class="headerlink" title="核心组件"></a>核心组件</h2><p><img src="/workspace/blog/source/images/Scrapy%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/e1868b22bb82ef7f1eacb68dc2086499.png" alt="img"></p>
<p>上面组件包括：</p>
<ul>
<li>引擎(<code>Scrapy Engine</code>)：用来处理整个系统的数据流处理, 触发事务(框架核心)；</li>
<li>调度器(<code>Scheduler</code>)：用来接受引擎发过来的请求, 压入队列中, 并在引擎再次请求的时候返回. 可以想像成一个<code>URL</code>（抓取网页的网址或者说是链接）的优先队列, 由它来决定下一个要抓取的网址是什么, 同时去除重复的网址；</li>
<li>下载器(<code>Downloader</code>)：用于下载网页内容, 并将网页内容返回给蜘蛛(<code>Scrapy</code>下载器是建立在<code>twisted</code>这个高效的异步模型上的)；</li>
<li>爬虫(<code>Spiders</code>)：爬虫是主要干活的, 用于从特定的网页中提取自己需要的信息, 即所谓的实体(<code>Item</code>)。用户也可以从中提取出链接,让<code>Scrapy</code>继续抓取下一个页面；</li>
<li>项目管道(<code>Pipeline</code>)：负责处理爬虫从网页中抽取的实体，主要的功能是持久化实体、验证实体的有效性、清除不需要的信息。当页面被爬虫解析后，将被发送到项目管道，并经过几个特定的次序处理数据；</li>
</ul>
<h2 id="代码编写"><a href="#代码编写" class="headerlink" title="代码编写"></a>代码编写</h2><p>代码编写流程如下:</p>
<ol>
<li>编写<code>item</code>用于封装解析到的数据；</li>
<li>编写<code>spider</code>用于指定访问的<code>url</code>和解析请求到的数据并将数据封装成<code>item</code>对象；</li>
<li>编写<code>pipeline</code>用于对<code>item</code>进行处理，一般是持久化；</li>
<li>编写<code>middleware</code>，一般用于配置代理以及<code>user-agent</code>等；</li>
</ol>
<h3 id="数据封装对象"><a href="#数据封装对象" class="headerlink" title="数据封装对象"></a>数据封装对象</h3><p>根据自身需求定义<code>item</code>类，封装需要的数据</p>
<p>下面例子是将文章封面图的<code>link</code>以及文章的<code>title</code>封装成<code>item</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 封装文章数据</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ArticleItem</span>(scrapy.Item):</span><br><span class="line">    <span class="comment"># 属性的定义方式如下:</span></span><br><span class="line">    <span class="comment"># name = scrapy.Field()</span></span><br><span class="line">    title = scrapy.Field()</span><br><span class="line">    link = scrapy.Field()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 封装文章图片地址</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ArticleImageItem</span>(scrapy.Item):</span><br><span class="line">    src = scrapy.Field()</span><br></pre></td></tr></table></figure>

<h3 id="爬虫文件"><a href="#爬虫文件" class="headerlink" title="爬虫文件"></a>爬虫文件</h3><p>爬虫文件中定义了将要请求的url以及页面数据的解析逻辑</p>
<p>下面是用于爬取b站某页专栏的代码，省略了解析表达式和网址</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">BilibiliSpider</span>(scrapy.Spider):</span><br><span class="line">    name = <span class="string">&#x27;bilibili&#x27;</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;www.bilibili.com&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># url方式一：初始请求数组</span></span><br><span class="line">    <span class="comment"># start_urls = [&#x27;https://www.xxx.com/xxx&#x27;]</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># url方式二：start_requests()方法发起请求</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">start_requests</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Spider--start_requests()&#x27;</span>)</span><br><span class="line">        <span class="comment"># 爬取多页数据</span></span><br><span class="line">        <span class="keyword">for</span> page <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">2</span>):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Spider--start_requests()--for&#x27;</span>)</span><br><span class="line">            <span class="comment"># 手动发起请求，每次请求一个url，使用模板字符串拼接页数</span></span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(<span class="string">f&#x27;https://search.bilibili.com/article?vt=67519417&amp;keyword=%E5%A4%8F%E6%97%A5%E9%87%8D%E7%8E%B0&amp;from_source=webtop_search&amp;spm_id_from=333.1007&amp;search_source=2&amp;page=<span class="subst">&#123;page&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">parse</span>(<span class="params">self, response: HtmlResponse</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Spider--parse()&#x27;</span>)</span><br><span class="line">        list_items = response.css(<span class="string">&#x27;body &gt; #server-search-app .body-contain .article-item&#x27;</span>)</span><br><span class="line">        <span class="keyword">for</span> list_item <span class="keyword">in</span> list_items:</span><br><span class="line">            article_item = ArticleItem()</span><br><span class="line">            <span class="comment"># css()和xpath()方法返回的是selector列表</span></span><br><span class="line">            <span class="comment"># extract()方法将selector列表解析成字符串列表</span></span><br><span class="line">            <span class="comment"># extract_first()方法将selector列表中第一个数据解析成字符串并返回该字符串</span></span><br><span class="line">            article_item[<span class="string">&#x27;link&#x27;</span>] = list_item.css(<span class="string">&#x27;a img::attr(src)&#x27;</span>).extract_first()</span><br><span class="line">            article_item[<span class="string">&#x27;title&#x27;</span>] = list_item.css(<span class="string">&#x27;.content &gt;.headline&gt;a::attr(title)&#x27;</span>).extract_first()</span><br><span class="line">            article_url = <span class="string">&quot;https:&quot;</span> + list_item.css(<span class="string">&#x27;.content &gt;.headline &gt; a::attr(href)&#x27;</span>).extract_first()</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Spider--parse()--for&#x27;</span>)</span><br><span class="line">            <span class="comment"># 将article_item信息发送到管道</span></span><br><span class="line">            <span class="keyword">yield</span> article_item</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 调用parse_article()方法解析详细信息</span></span><br><span class="line">            <span class="comment"># 请求传惨：通过meta参数传递一个map，目标方法可以接收</span></span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(article_url, self.parse_article_image, meta=&#123;<span class="string">&#x27;article_item&#x27;</span>: article_item&#125;)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 自定义解析文章详情页的方法，用于提取图片</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">parse_article_image</span>(<span class="params">self, response</span>):</span><br><span class="line">        <span class="comment"># 获取传递的参数</span></span><br><span class="line">        article_item = response.meta[<span class="string">&#x27;article_item&#x27;</span>]</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;获取文章《<span class="subst">&#123;article_item[<span class="string">&#x27;title&#x27;</span>]&#125;</span>》的图片&quot;</span>)</span><br><span class="line">        figure_list = response.css(<span class="string">&#x27;#article-content &gt; #read-article-holder figure&#x27;</span>)</span><br><span class="line">        <span class="keyword">for</span> figure_item <span class="keyword">in</span> figure_list:</span><br><span class="line">            image_url = <span class="string">&quot;https:&quot;</span> + figure_item.css(<span class="string">&#x27;::attr(data-src)&#x27;</span>).extract_first()</span><br><span class="line">            image_item = ArticleImageItem()</span><br><span class="line">            image_item[<span class="string">&#x27;src&#x27;</span>] = image_url</span><br><span class="line">            <span class="keyword">yield</span> image_item</span><br></pre></td></tr></table></figure>

<h3 id="管道"><a href="#管道" class="headerlink" title="管道"></a>管道</h3><p>需要先配置开启管道</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 开启管道</span></span><br><span class="line"><span class="comment"># 可以配置任意个管道类，会按照优先级从小到大进行执行</span></span><br><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">    <span class="comment"># 管道类全类名: 优先级</span></span><br><span class="line">    <span class="string">&#x27;bilibili_test.pipelines.MysqlPipeline&#x27;</span>: <span class="number">300</span>,</span><br><span class="line">    <span class="string">&#x27;bilibili_test.pipelines.ArticleImagePipeline&#x27;</span>: <span class="number">301</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>下面定义了两个管道：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将文章信息存储到mysql数据库</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MysqlPipeline</span>:</span><br><span class="line">    <span class="comment"># 数据库连接</span></span><br><span class="line">    conn = <span class="literal">None</span></span><br><span class="line">    <span class="comment"># 数据库游标多谢</span></span><br><span class="line">    cursor = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 该方法会在爬虫开始时被调用并且只会被调用一次</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">open_spider</span>(<span class="params">self, spider</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;mysql管道--open_spider()&#x27;</span>)</span><br><span class="line">        self.conn = pymysql.Connect(</span><br><span class="line">            host=<span class="string">&#x27;127.0.0.1&#x27;</span>,</span><br><span class="line">            port=<span class="number">3306</span>,</span><br><span class="line">            user=<span class="string">&#x27;root&#x27;</span>,</span><br><span class="line">            password=<span class="string">&#x27;123456&#x27;</span>,</span><br><span class="line">            db=<span class="string">&#x27;scrapy_test&#x27;</span>,</span><br><span class="line">            charset=<span class="string">&#x27;utf8&#x27;</span>,</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 接收爬虫文件传递过来的item对象</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_item</span>(<span class="params">self, item: ArticleItem, spider</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;mysql管道--process_item()&#x27;</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(item, ArticleItem):</span><br><span class="line">            <span class="comment"># 如果不是需要的类型，直接发送到下一个管道</span></span><br><span class="line">            <span class="keyword">return</span> item</span><br><span class="line">        <span class="comment"># 写入文件</span></span><br><span class="line">        self.cursor = self.conn.cursor()</span><br><span class="line">        <span class="comment"># 插入到mysql</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            self.cursor.execute(<span class="string">&#x27;insert into article(title,link) values(&quot;%s&quot;,&quot;%s&quot;)&#x27;</span> % (item[<span class="string">&quot;title&quot;</span>], item[<span class="string">&quot;link&quot;</span>]))</span><br><span class="line">            self.conn.commit()</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(e)</span><br><span class="line">            self.conn.rollback()</span><br><span class="line">        <span class="keyword">return</span> item</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 爬虫结束后会调用一次</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">close_spider</span>(<span class="params">self, spider</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;mysql管道--close_spider()&#x27;</span>)</span><br><span class="line">        self.conn.close()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 声明父类是ImagesPipeline</span></span><br><span class="line"><span class="comment"># ImagesPipeline是scrapy提供的专门用于图片存储的管道类</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ArticleImagePipeline</span>(<span class="title class_ inherited__">ImagesPipeline</span>):</span><br><span class="line">    <span class="comment"># 根据图片地址进行图片数据的请求</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_media_requests</span>(<span class="params">self, item, info</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;图片下载管道--get_media_requests()&#x27;</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(item, ArticleImageItem):</span><br><span class="line">            <span class="comment"># 如果不是需要的类型，直接发送到下一个管道</span></span><br><span class="line">            <span class="keyword">return</span> item</span><br><span class="line">        <span class="comment"># 获取图片</span></span><br><span class="line">        <span class="keyword">yield</span> scrapy.Request(item[<span class="string">&#x27;src&#x27;</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 指定文件存储位置</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">file_path</span>(<span class="params">self, request, response=<span class="literal">None</span>, info=<span class="literal">None</span>, *, item=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;图片下载管道--file_path()&#x27;</span>)</span><br><span class="line">        imageName = request.url.split(<span class="string">&#x27;/&#x27;</span>)[-<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">return</span> imageName</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 用于该管道执行结束向下一个将要执行的管道传递数据</span></span><br><span class="line">    <span class="comment"># 如果不需要传递数据，则这个方法可以不重写</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">item_completed</span>(<span class="params">self, results, item, info</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;图片下载管道--item_completed()&#x27;</span>)</span><br><span class="line">        <span class="comment"># 把当前的item传递给下一个管道类</span></span><br><span class="line">        <span class="keyword">return</span> item</span><br></pre></td></tr></table></figure>

<h3 id="中间件"><a href="#中间件" class="headerlink" title="中间件"></a>中间件</h3><p>需要先配置开启管道</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 开启爬虫中间件</span></span><br><span class="line">SPIDER_MIDDLEWARES = &#123;</span><br><span class="line">   <span class="string">&#x27;bilibili_test.middlewares.BilibiliTestSpiderMiddleware&#x27;</span>: <span class="number">543</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开启下载中间件</span></span><br><span class="line">DOWNLOADER_MIDDLEWARES = &#123;</span><br><span class="line">    <span class="string">&#x27;bilibili_test.middlewares.BilibiliTestDownloaderMiddleware&#x27;</span>: <span class="number">543</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>中间件有两个</p>
<ul>
<li>爬虫中间件</li>
<li>下载中间件</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line">proxy_ip_list = [</span><br><span class="line">    <span class="string">&#x27;47.92.113.71:80&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;117.157.197.18:3128&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;111.23.16.250:3128&#x27;</span>,</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">user_agent_list = [</span><br><span class="line">    <span class="string">&quot;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 &quot;</span></span><br><span class="line">    <span class="comment"># ......</span></span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 爬虫中间件</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BilibiliTestSpiderMiddleware</span>:</span><br><span class="line"></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">from_crawler</span>(<span class="params">cls, crawler</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;爬虫中间件--from_crawler()&#x27;</span>)</span><br><span class="line">        s = cls()</span><br><span class="line">        crawler.signals.connect(s.spider_opened, signal=signals.spider_opened)</span><br><span class="line">        <span class="keyword">return</span> s</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_spider_input</span>(<span class="params">self, response, spider</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;爬虫中间件--process_spider_input()&#x27;</span>)</span><br><span class="line">        <span class="comment"># 返回None或一个异常</span></span><br><span class="line">        <span class="comment"># 如果是None,就继续调用其他的spider middleware。</span></span><br><span class="line">        <span class="comment"># 如果是一个异常，调用request里的errback()方法，再抛出异常是交给process_spider_exception(response, exception, spider)处理</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_spider_output</span>(<span class="params">self, response, result, spider</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;爬虫中间件--process_spider_output()&#x27;</span>)</span><br><span class="line">        <span class="comment"># 必须返回一个包括request或item对象的可迭代对象</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> result:</span><br><span class="line">            <span class="keyword">yield</span> i</span><br><span class="line">	<span class="comment"># 当spider或其他中间件的process_spider_input()报错时被调用</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_spider_exception</span>(<span class="params">self, response, exception, spider</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;爬虫中间件--process_spider_exception()&#x27;</span>)</span><br><span class="line">        <span class="comment"># 应该返回 None 或一个可迭代的 Request 或 item 对象</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 爬虫启动请求</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_start_requests</span>(<span class="params">self, start_requests, spider</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;爬虫中间件--process_start_requests()&#x27;</span>)</span><br><span class="line">        <span class="comment"># 只能返回request对象</span></span><br><span class="line">        <span class="keyword">for</span> r <span class="keyword">in</span> start_requests:</span><br><span class="line">            <span class="keyword">yield</span> r</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">spider_opened</span>(<span class="params">self, spider</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;爬虫中间件--spider_opened()&#x27;</span>)</span><br><span class="line">        spider.logger.info(<span class="string">&#x27;Spider opened: %s&#x27;</span> % spider.name)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载中间件</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BilibiliTestDownloaderMiddleware</span>:</span><br><span class="line"></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">from_crawler</span>(<span class="params">cls, crawler</span>):</span><br><span class="line">        <span class="comment"># Scrapy 使用此方法来创建爬虫</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;下载中间件--from_crawler()&#x27;</span>)</span><br><span class="line">        s = cls()</span><br><span class="line">        crawler.signals.connect(s.spider_opened, signal=signals.spider_opened)</span><br><span class="line">        <span class="keyword">return</span> s</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 拦截请求，当每个request通过下载中间件时，该方法被调用</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_request</span>(<span class="params">self, request, spider</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;下载中间件--process_request()&#x27;</span>)</span><br><span class="line">        <span class="comment"># 随机选择user-agent</span></span><br><span class="line">        ua = random.choice(user_agent_list)</span><br><span class="line">        <span class="comment"># 设置请求的ua</span></span><br><span class="line">        request.headers[<span class="string">&#x27;User-Agent&#x27;</span>] = ua</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 拦截响应，</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_response</span>(<span class="params">self, request, response, spider</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;下载中间件--process_response()&#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span> response</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 拦截发生异常的请求</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_exception</span>(<span class="params">self, request, exception, spider</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;下载中间件--process_exception()&#x27;</span>)</span><br><span class="line">        <span class="comment"># 请求失败就设置代理ip</span></span><br><span class="line">        <span class="keyword">if</span> request.url.split(<span class="string">&#x27;:&#x27;</span>) == <span class="string">&#x27;https&#x27;</span>:</span><br><span class="line">            <span class="comment"># 设置代理ip</span></span><br><span class="line">            request.meta[<span class="string">&#x27;proxy&#x27;</span>] = <span class="string">&#x27;https//&#x27;</span> + random.choice(proxy_ip_list)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            request.meta[<span class="string">&#x27;proxy&#x27;</span>] = <span class="string">&#x27;http//&#x27;</span> + random.choice(proxy_ip_list)</span><br><span class="line">        <span class="comment"># 返回request会重新进行请求发送</span></span><br><span class="line">        <span class="keyword">return</span> request</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">spider_opened</span>(<span class="params">self, spider</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;下载中间件--spider_opened()&#x27;</span>)</span><br><span class="line">        spider.logger.info(<span class="string">&#x27;Spider opened: %s&#x27;</span> % spider.name)</span><br></pre></td></tr></table></figure>

<h2 id="执行顺序"><a href="#执行顺序" class="headerlink" title="执行顺序"></a>执行顺序</h2><p>下面的爬虫中间件和下载中间件均的优先级相同；下列执行步骤中如果定义了多个管道，则会按照设置的优先值从小到大执行，并且位置是相邻的</p>
<p><strong>初始化执行部分</strong>：</p>
<ol>
<li>下载中间件–<code>from_crawler()</code></li>
<li>爬虫中间件–<code>from_crawler()</code></li>
<li>管道–<code>open_spider()</code></li>
<li>下载中间件–<code>spider_opened()</code></li>
<li>爬虫中间件–<code>spider_opened()</code></li>
</ol>
<p><strong>爬虫开始部部分</strong>：</p>
<ol>
<li>爬虫中间件–<code>process_start_requests()</code></li>
<li><code>Spider--start_requests()</code></li>
<li><code>Spider--start_requests()--for</code></li>
<li>下载中间件–<code>process_request()</code></li>
<li>下载中间件–<code>process_response()</code></li>
<li>爬虫中间件–<code>process_spider_input()</code></li>
<li>爬虫中间件–<code>process_spider_output()</code></li>
<li><code>Spider--parse()</code></li>
<li><code>Spider--parse()--for</code></li>
<li>管道<code>process_item()</code></li>
<li><code>Spider--parse()--for</code></li>
<li>管道–<code>process_item()</code></li>
<li>下载中间件–<code>process_request()</code>（调用<code>scrapy.Request()</code>触发该方法）</li>
<li><code>Spider--parse()--for</code></li>
<li>……</li>
</ol>
</div><div class="article-licensing box"><div class="licensing-title"><p>Scrapy 基础知识</p><p><a href="http://example.com/2022/09/24/language/Python/Scrapy/Scrapy使用方式/">http://example.com/2022/09/24/language/Python/Scrapy/Scrapy使用方式/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>路由器</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2022-09-24</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2022-09-26</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/%E7%88%AC%E8%99%AB/">爬虫</a></div></article></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2022/09/17/tools/Kubernetes/Kubernetes%E9%83%A8%E7%BD%B2/"><span class="level-item">Kubernetes 部署</span><i class="level-item fas fa-chevron-right"></i></a></div></nav></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/avatar.png" alt="路由器"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">路由器</p><p class="is-size-6 is-block">笔记</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>M78</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">33</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">13</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">15</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/zcy626727" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/zcy626727"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">链接</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://hexo.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Hexo</span></span><span class="level-right"><span class="level-item tag">hexo.io</span></span></a></li><li><a class="level is-mobile" href="https://bulma.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Bulma</span></span><span class="level-right"><span class="level-item tag">bulma.io</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/Java/"><span class="level-start"><span class="level-item">Java</span></span><span class="level-end"><span class="level-item tag">23</span></span></a><ul><li><a class="level is-mobile" href="/categories/Java/Spring/"><span class="level-start"><span class="level-item">Spring</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/categories/Java/Spring-Boot/"><span class="level-start"><span class="level-item">Spring Boot</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile" href="/categories/Java/Spring-Boots/"><span class="level-start"><span class="level-item">Spring Boots</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Java/Spring-MVC/"><span class="level-start"><span class="level-item">Spring MVC</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Kubernetes/"><span class="level-start"><span class="level-item">Kubernetes</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/Linux/"><span class="level-start"><span class="level-item">Linux</span></span><span class="level-end"><span class="level-item tag">4</span></span></a><ul><li><a class="level is-mobile" href="/categories/Linux/Fedora/"><span class="level-start"><span class="level-item">Fedora</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Linux/Ubuntu/"><span class="level-start"><span class="level-item">Ubuntu</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Python/"><span class="level-start"><span class="level-item">Python</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/Python/Scrapy/"><span class="level-start"><span class="level-item">Scrapy</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"><span class="level-start"><span class="level-item">数据库</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/Redis/"><span class="level-start"><span class="level-item">Redis</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-09-23T16:00:00.000Z">2022-09-24</time></p><p class="title"><a href="/2022/09/24/language/Python/Scrapy/Scrapy%E4%BD%BF%E7%94%A8%E6%96%B9%E5%BC%8F/">Scrapy 基础知识</a></p><p class="categories"><a href="/categories/Python/">Python</a> / <a href="/categories/Python/Scrapy/">Scrapy</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-09-17T05:18:16.000Z">2022-09-17</time></p><p class="title"><a href="/2022/09/17/tools/Kubernetes/Kubernetes%E9%83%A8%E7%BD%B2/">Kubernetes 部署</a></p><p class="categories"><a href="/categories/Kubernetes/">Kubernetes</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-06-25T14:54:00.000Z">2022-06-25</time></p><p class="title"><a href="/2022/06/25/linux/fedora/fedora%20%E5%AD%98%E5%82%A8%E5%BA%93/">Fedora 包管理器</a></p><p class="categories"><a href="/categories/Linux/">Linux</a> / <a href="/categories/Linux/Fedora/">Fedora</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-06-24T16:00:00.000Z">2022-06-25</time></p><p class="title"><a href="/2022/06/25/linux/fedora/feaora%E5%88%9D%E5%A7%8B%E5%8C%96%E9%85%8D%E7%BD%AE/">Fedora 初始化配置</a></p><p class="categories"><a href="/categories/Linux/">Linux</a> / <a href="/categories/Linux/Fedora/">Fedora</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-05-29T07:46:22.000Z">2022-05-29</time></p><p class="title"><a href="/2022/05/29/linux/ubuntu/Ubuntu%20%E5%88%9D%E5%A7%8B%E5%8C%96%E9%85%8D%E7%BD%AE/">Ubuntu 初始化配置</a></p><p class="categories"><a href="/categories/Linux/">Linux</a> / <a href="/categories/Linux/Ubuntu/">Ubuntu</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">归档</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2022/09/"><span class="level-start"><span class="level-item">九月 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/06/"><span class="level-start"><span class="level-item">六月 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/05/"><span class="level-start"><span class="level-item">五月 2022</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/01/"><span class="level-start"><span class="level-item">一月 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/12/"><span class="level-start"><span class="level-item">十二月 2021</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/06/"><span class="level-start"><span class="level-item">六月 2021</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/05/"><span class="level-start"><span class="level-item">五月 2021</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/04/"><span class="level-start"><span class="level-item">四月 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/03/"><span class="level-start"><span class="level-item">三月 2021</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/01/"><span class="level-start"><span class="level-item">一月 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/12/"><span class="level-start"><span class="level-item">十二月 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/10/"><span class="level-start"><span class="level-item">十月 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/09/"><span class="level-start"><span class="level-item">九月 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/08/"><span class="level-start"><span class="level-item">八月 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/07/"><span class="level-start"><span class="level-item">七月 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/06/"><span class="level-start"><span class="level-item">六月 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/05/"><span class="level-start"><span class="level-item">五月 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/03/"><span class="level-start"><span class="level-item">三月 2020</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/02/"><span class="level-start"><span class="level-item">二月 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">标签</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/Fedora/"><span class="tag">Fedora</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Kubernetes/"><span class="tag">Kubernetes</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Redis/"><span class="tag">Redis</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/SpringBootWeb%E6%A1%86%E6%9E%B6%E9%9B%86%E6%88%90/"><span class="tag">SpringBootWeb框架集成</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/SpringBoot%E6%95%B0%E6%8D%AE%E5%BA%93%E9%9B%86%E6%88%90/"><span class="tag">SpringBoot数据库集成</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/SpringBoot%E6%A0%B8%E5%BF%83%E5%8A%9F%E8%83%BD/"><span class="tag">SpringBoot核心功能</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/SpringBoot%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/"><span class="tag">SpringBoot源码解析</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Spring%E6%95%B0%E6%8D%AE%E8%AE%BF%E9%97%AE/"><span class="tag">Spring数据访问</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Spring%E6%A0%B8%E5%BF%83%E5%8A%9F%E8%83%BD/"><span class="tag">Spring核心功能</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Spring%E6%B3%A8%E8%A7%A3/"><span class="tag">Spring注解</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Ubuntu/"><span class="tag">Ubuntu</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/fedora/"><span class="tag">fedora</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%8C%85%E7%AE%A1%E7%90%86%E5%99%A8/"><span class="tag">包管理器</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%88%AC%E8%99%AB/"><span class="tag">爬虫</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"><span class="tag">环境配置</span><span class="tag">2</span></a></div></div></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/avatar.png" alt="路由器" height="28"></a><p class="is-size-7"><span>&copy; 2022 路由器</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>